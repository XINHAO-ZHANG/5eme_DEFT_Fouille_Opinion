# 预处理

对于这个文本分类任务，我们需要的仅有“文本”+“标签”。因此，对于原有的xml文件，我们首先提取了训练集每个doc标签下的text标签以及其对应的政党类别，通过列表嵌套字典转换成为DataFrame对象，并输出为csv格式文件。
对于测试集，我们结合xml文件以及对应的label文本文件，同样获得了相同格式的csv文件，这有助于结构清晰化和开展接下来的文本预处理。



在文本预处理阶段，我们使用nltk规范了大小写，删除了停用词，特殊符号以及数字，因为这些内容对分类任务无帮助。我们将处理好的文本封装到新的csv文件。

在特征选择阶段，我们使用了tfidf来进行文本向量化。在对于功能进行参数设置时，我们选择        max_df=0.6，进一步过滤掉出现频率较高的词。





1. **Accuracy（准确率）**：
   - Accuracy 是最常见的分类性能指标之一，表示模型正确分类样本的比例。它是一个总体指标，用于衡量模型的整体性能。
   - 公式：(True Positives + True Negatives) / (True Positives + True Negatives + False Positives + False Negatives)
   - 举例：如果有100个样本，模型正确分类了90个，准确率就是90%。
2. **Kappa Score（Kappa系数）**：
   - Kappa 系数是用于度量模型性能的一种统计度量，它考虑了模型的性能是否超出了随机水平。Kappa 系数的取值范围为[-1, 1]，其中1表示完美一致，0表示与随机性一致，-1表示完全不一致。
   - 举例：如果 Kappa 系数为0.6，表示模型的性能比随机选择好，但不是完美的一致性。
3. **Precision（精确率）**：
   - 精确率是指模型在预测为正例的样本中，有多少是真正的正例。它衡量了模型的预测有多少是准确的。
   - 公式：True Positives / (True Positives + False Positives)
   - 举例：如果模型预测有10个样本是正例，而其中有8个确实是正例，精确率为0.8。
4. **Recall（召回率）**：
   - 召回率是指模型正确预测的正例占所有真正正例的比例。它衡量了模型是否能够捕捉到所有正例。
   - 公式：True Positives / (True Positives + False Negatives)
   - 举例：如果有100个真正的正例，而模型成功预测了其中的80个，召回率为0.8。
5. **F1-Score（F1值）**：
   - F1值是精确率和召回率的调和平均数，它可以帮助平衡精确率和召回率之间的权衡。
   - 公式：2 * (Precision * Recall) / (Precision + Recall)
   - 举例：如果精确率为0.75，召回率为0.80，那么F1值为0.77。





# 过拟合问题

早停策略

学习曲线



# Variables à considérer



**N-grams** dans TF-IDF：`ngram_range`: 您选择了(1,1)，这意味着仅考虑单个单词。在一些情况下，考虑双词组（bigrams, `ngram_range=(1,2)`）可能会提供更多上下文信息，但这也会显著增加特征的数量。

**max_features**: 限制特征的数量为50000，这有助于减少模型的复杂性和训练时间，但也可能遗漏一些重要特征。您可能需要根据模型的性能来调整这个参数。



**进一步的优化**：可以尝试不同的预处理和特征工程技术，如停用词移除、词干提取、词性标注等，以看看它们是否能提高模型的性能。















任务的背景



经验（方法和结果）



结论







# 其他尝试

除了tfidf 尝试词嵌入 Word2vec glove





交叉验证是一种用于评估和选择机器学习模型性能的技术。它在模型训练和性能评估的各个环节都可以应用，但主要用于以下两个方面：

1. **模型性能评估**：
   - 交叉验证用于评估模型的性能，特别是在有限数据集上。它通过将数据集分成多个不重叠的子集，然后多次训练和验证模型，以获得多个性能评估的指标。最常见的交叉验证方法是K折交叉验证。
   - K折交叉验证的步骤如下：
     1. 将数据集分成K个（通常是5或10）相似大小的子集，称为“折叠”（folds）。
     2. 对于K次迭代，将其中一个折叠用作验证集，其余的K-1个折叠用作训练集。
     3. 在每次迭代中，训练模型并在验证集上评估性能。
     4. 最后，计算K次迭代的性能评估指标的平均值（如准确度、精确度、召回率等）来估计模型的性能。
2. **模型选择和调优**：
   - 交叉验证也用于选择和调优模型的超参数。通过在不同的参数设置下进行多次交叉验证，可以找到最佳的超参数配置，以获得最佳的模型性能。
   - 例如，在网格搜索（Grid Search）中，可以定义超参数的候选值范围，然后使用交叉验证来评估每个超参数组合的性能。最终，选择在验证集上性能最佳的超参数组合。

应用交叉验证的时机包括：

- 模型训练：在训练模型之前，使用交叉验证来评估模型的性能。
- 模型选择和调优：在选择最佳模型或调整超参数时，使用交叉验证来比较不同模型或参数配置的性能。

**交叉验证有助于更准确地估计模型的性能，避免过度拟合（overfitting）和提高模型的泛化能力。它在机器学习和深度学习中是一个重要的评估工具。**





- 如果您希望使用神经网络模型，但计算资源有限，可以考虑构建较小的神经网络，如浅层CNN或单层LSTM。这些模型在一些任务中也能够取得不错的性能。
- 此外，您可以使用预训练的小型模型，如DistilBERT，它是BERT的轻量级版本，对计算资源要求相对较低。









# RF

但是，我们在构建该分类器时也遇到了一些问题：首先，随机森林算法的参数设置比较复杂，存在多个参数需要调节，而由于我们的语料库为高维向量，且规模较大，这导致在进行超参数求解的过程中耗费了大量时长。在这一过程中，尽管我们调节了random_state以稳定结果，但执行交叉验证＋Grid Search求**n_estimators**、max_depth等参数仍然需要消耗大量的时间和算力；其次，由于随机性，每次训练随机森林时，即使其他参数相同，最终的模型也可能略有不同，导致解释性较差。



我们获得的结果基本能总体上维持77以上的精确值，这是一个相对理想的数值。各个类别的精确率（Precision）和召回率（Recall）不均衡。例如，ELDR类的精确率很高（0.99），但召回率较低（0.62）。而对于样本数较多的PPE-DE类，其召回率很高（0.94），但精确率较低（0.67），这表明分类器倾向于将样本错误地归为样本比重较大的类。因此，我们尝试使用SMOTE进行重采样，但是结果并没有明显进步。

Class distribution origin: Counter({2: 6858, 3: 5436, 1: 2687, 4: 2376, 0: 2008})
Class distribution resampled: Counter({4: 6858, 2: 6858, 3: 6858, 0: 6858, 1: 6858})











# NB



朴素贝叶斯分类算法比较容易实现，而且分类效率高。由于这项任务是多类别文本分类问题，且特征变量为离散数据，因此我们选择多项式朴素贝叶斯。在其参数调整方面，首先我们发现，由于不同类别的样本数量存在差异，因此学习率过高会导致零概率问题。所以我们将学习率设为0.001，且使用统一先验概率，获得了如下结果：

解读：

从结果中，我们发现在朴素贝叶斯下，样本数量并没有影响到分类性能，GUE-NGL获得了最好的结果，其准确率达到了0.81。

Dans les résultats, nous observons qu'il n'y a pas de corrélation évidente entre la taille du support et la performance. Par exemple, la classe PPE-DE a le plus grand nombre d'échantillons (4571), mais n'a pas nécessairement la meilleure performance en termes de précision ou de score F1.



Cette classe a de meilleurs résultats avec une précision de 0.81, un rappel de 0.73 et un score F1 de 0.77. Le support est de 1792.







同时，我们认为





类：

多项式朴素贝叶斯

的实现。

- 适用于特征变量是离散型数据，符合多项分布。在文档分类中特征变量体现在一个单词出现的次数，或者是单词的 TF-IDF 值等。





1. - 如果您的数据是多类别文本分类问题，通常使用多项式朴素贝叶斯。如果您的数据是二分类问题，您可以尝试使用伯努利朴素贝叶斯。