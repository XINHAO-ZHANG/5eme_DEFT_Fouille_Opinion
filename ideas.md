对于这个文本分类任务，我们需要的仅有“文本”+“标签”。因此，对于原有的xml文件，我们首先提取了训练集每个doc标签下的text标签以及其对应的政党类别，通过列表嵌套字典转换成为DataFrame对象，并输出为csv格式文件。
对于测试集，我们结合xml文件以及对应的label文本文件，同样获得了相同格式的csv文件，这有助于结构清晰化和开展接下来的文本预处理。



在文本预处理阶段，我们使用nltk规范了大小写，删除了停用词，特殊符号以及数字，因为这些内容对分类任务无帮助。我们将处理好的文本封装到新的csv文件。

在特征选择阶段，我们使用了tfidf来进行文本向量化。在对于功能进行参数设置时，我们选择        max_df=0.6，进一步过滤掉出现频率较高的词。











# Variables à considérer



**N-grams** dans TF-IDF：`ngram_range`: 您选择了(1,1)，这意味着仅考虑单个单词。在一些情况下，考虑双词组（bigrams, `ngram_range=(1,2)`）可能会提供更多上下文信息，但这也会显著增加特征的数量。

**max_features**: 限制特征的数量为50000，这有助于减少模型的复杂性和训练时间，但也可能遗漏一些重要特征。您可能需要根据模型的性能来调整这个参数。



**进一步的优化**：您可以尝试不同的预处理和特征工程技术，如停用词移除、词干提取、词性标注等，以看看它们是否能提高模型的性能。















任务的背景



经验（方法和结果）



结论







# 其他尝试

除了tfidf 尝试词嵌入 Word2vec glove





交叉验证是一种用于评估和选择机器学习模型性能的技术。它在模型训练和性能评估的各个环节都可以应用，但主要用于以下两个方面：

1. **模型性能评估**：
   - 交叉验证用于评估模型的性能，特别是在有限数据集上。它通过将数据集分成多个不重叠的子集，然后多次训练和验证模型，以获得多个性能评估的指标。最常见的交叉验证方法是K折交叉验证。
   - K折交叉验证的步骤如下：
     1. 将数据集分成K个（通常是5或10）相似大小的子集，称为“折叠”（folds）。
     2. 对于K次迭代，将其中一个折叠用作验证集，其余的K-1个折叠用作训练集。
     3. 在每次迭代中，训练模型并在验证集上评估性能。
     4. 最后，计算K次迭代的性能评估指标的平均值（如准确度、精确度、召回率等）来估计模型的性能。
2. **模型选择和调优**：
   - 交叉验证也用于选择和调优模型的超参数。通过在不同的参数设置下进行多次交叉验证，可以找到最佳的超参数配置，以获得最佳的模型性能。
   - 例如，在网格搜索（Grid Search）中，可以定义超参数的候选值范围，然后使用交叉验证来评估每个超参数组合的性能。最终，选择在验证集上性能最佳的超参数组合。

应用交叉验证的时机包括：

- 模型训练：在训练模型之前，使用交叉验证来评估模型的性能。
- 模型选择和调优：在选择最佳模型或调整超参数时，使用交叉验证来比较不同模型或参数配置的性能。

**交叉验证有助于更准确地估计模型的性能，避免过度拟合（overfitting）和提高模型的泛化能力。它在机器学习和深度学习中是一个重要的评估工具。**





- 如果您希望使用神经网络模型，但计算资源有限，可以考虑构建较小的神经网络，如浅层CNN或单层LSTM。这些模型在一些任务中也能够取得不错的性能。
- 此外，您可以使用预训练的小型模型，如DistilBERT，它是BERT的轻量级版本，对计算资源要求相对较低。









1. ```
   naive_bayes.MultinomialNB
   ```

    

   类：

   多项式朴素贝叶斯

   的实现。

   - 适用于特征变量是离散型数据，符合多项分布。在文档分类中特征变量体现在一个单词出现的次数，或者是单词的 TF-IDF 值等。





1. - 如果您的数据是多类别文本分类问题，通常使用多项式朴素贝叶斯。如果您的数据是二分类问题，您可以尝试使用伯努利朴素贝叶斯。